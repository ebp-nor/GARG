{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b825ca5-56f8-463a-b272-e6e31de08c6a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To access material for this workbook please execute the two notebook cells immediately below (e.g. use the shortcut <b>&lt;shift&gt;+&lt;return&gt;</b>). The first cell can be skipped if you are running this notebook locally and have already installed all the necessary packages. The second cell should print out \"Your notebook is ready to go!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc9395-655a-42a0-ac17-ab2b73d009be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pyodide_kernel' in str(get_ipython()):  # specify packages to install under JupyterLite\n",
    "    raise RuntimeError(\"This workbook is not designed to run in JupyterLite. Please use a Colab or local install\")\n",
    "elif 'google.colab' in str(get_ipython()):  # specify package location for loading in Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %run /content/drive/MyDrive/GARG_workshop/Notebooks/add_module_path.py\n",
    "else:  # install packages on your local machine (-q = \"quiet\": don't print out installation steps)\n",
    "    !python -m pip install -q -r https://github.com/ebp-nor/GARG/raw/main/jlite/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2d58c-61d9-4286-946d-c717857f2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load questions etc for this workbook\n",
    "from IPython.display import SVG\n",
    "import tskit\n",
    "import ARG_workshop\n",
    "workbook = ARG_workshop.Workbook1D()\n",
    "display(workbook.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65c0e5-86d2-49d8-a8fd-2cce003fd0cf",
   "metadata": {},
   "source": [
    "### Using this workbook\n",
    "\n",
    "This workbook is intended to be used by executing each cell as you go along. Code cells (like those above) can be modified and re-executed to perform different behaviour or additional analysis. You can use this to complete various programming exercises, some of which have associated questions to test your understanding. Exercises are marked like this:\n",
    "<dl class=\"exercise\"><dt>Exercise XXX</dt>\n",
    "<dd>Here is an exercise: normally there will be a code cell below this box for you to work in</dd>\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e3c291-8534-408a-9e33-22fb34cc5470",
   "metadata": {},
   "source": [
    "# Workbook 2-C: ARG inference\n",
    "\n",
    "Although ARG inference is a difficult problem, a number of software programs have been developed in recent years that make a reasonable job at ARG inference. Currently, we recommend either [_SINGER_](https://github.com/popgenmethods/SINGER) (for smaller datasets) or [_tsinfer_](https://github.com/tskit-dev/tsinfer) (coupled with [_tsdate_](https://github.com/tskit-dev/tsdate)) for larger datasets. Both of these approaches output tree sequences. You might also like to consider [Relate](https://myersgroup.github.io/relate/), which has been used extensively in analysis of recent human history (and which can convert output, albeit inefficiently, to _tskit_ format). These three software programs have the same basic requirements: phased data and knowledge of the ancestral state, but are based on very different approaches.\n",
    "\n",
    "* ___SINGER___ takes a statistical sample of likely ARGs using MCMC sampling. That means it is pretty computationally intensive, so will only work on sample sizes of tens or hundreds of genomes. As _SINGER_ takes a sampling appraoch, it outputs multiple possible ARGs, which are sampled using the coalescent with recombination as a probabilistic model. Testing suggests that this provides the most accurate results.\n",
    "* ___Tsinfer___, in contrast, creates a single \"best guess\" ARG using a heuristic approach based on ancestor reconstruction. It does not attempt to estimate times of nodes in the ARG, and unlike _SINGER_, it is therefore not dependent on coalescent assumptions. For many purposes, node times are important, and a separate algorithm, _tsdate_, can be used to infer node times under the molecular clock. We will be use extremly recent versions of the two pieces of software, such that their offical documentation may not yet be up-to-date. The major drawback of the _tsinfer_+_tsdate_ approach is that rather than outputting multiple ARGs, it expresses uncertainty by using *polytomies* (nodes with more than one child). Many analysis approaches are not designed for use on trees with polytomies.\n",
    "* ___Relate___ also uses a heuristic approach, which essentially involves building separate trees along the genome and then combining them together (but this results in very inefficient tree sequences, with low amounts of correlation between adjacent trees). It also outputs a single ARG, but polytomies are fully resolved, even in the absence of strong evidence for how to resolve them. The accuracy of results is on a par with the latest _tsinfer_+_tsdate_.\n",
    "\n",
    "In this workbook, we will focus on using the fastest and most efficient method: _tsinfer_ + _tsdate_. Further, advanced workbooks will introduce _SINGER_. To illustrate, we will use the same simulation as we previously encountered, and inpect the quality of the inference by comparing the dates of the nodes below each mutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043bbba-99ed-4033-b80f-7c864796a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tskit\n",
    "simulated_ts = tskit.load(\"data/chimp_selection.trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2dfa32-b75c-4e8d-b9a4-1c12b02b6ffc",
   "metadata": {},
   "source": [
    "For efficiency reasons, _tsinfer_ reads data in the [VCF Zarr](https://github.com/sgkit-dev/vcf-zarr-spec/) format, which is designed to allow rapid processing of large amounts of genetic variant data. It should soon be possible to [convert tree sequences directly to this format](https://github.com/sgkit-dev/bio2zarr/issues/232), but for the moment, this needs to be done the slow way, by outputting to VCF and converting to a `.vcz` file using [vcf2zarr](https://sgkit-dev.github.io/bio2zarr/vcf2zarr/overview.html#sec-vcf2zarr) on the command-line. For ease of use in the workbook, the `ARG_workshop.ts2vcz` function will do the hard work for you. Remember that the data need to be *phased*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd684cb5-824f-47fd-822b-a6e054cf0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the .vcz file\n",
    "ARG_workshop.ts2vcz(simulated_ts, \"PanTro-chr3-sim.vcz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb5808-c341-4c66-a580-3ca62f844e30",
   "metadata": {},
   "source": [
    "Details for how to use for the new (currently alpha) version of `tsinfer` are at [https://tskit.dev/tsinfer/docs/latest/usage.html](https://tskit.dev/tsinfer/docs/latest/usage.html). Basically, we need to wrap the `.vcz` file in a `tsinfer.VariantData` object. This allows us to specify the ancestral allele, and mask out problematic sites or samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac2b5e-3206-4799-b34a-b7edc0c3c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsinfer\n",
    "import numpy as np\n",
    "\n",
    "# We must obtain the ancestral allele from somewhere. Here we use that given in the simulation\n",
    "# See https://github.com/tskit-dev/tsinfer/discussions/523 for more details\n",
    "ancestral_allele=np.array([s.ancestral_state for s in simulated_ts.sites()])\n",
    "\n",
    "# The VariantData interface is now the preferred way to create tsinfer input files (the old one was called SampleData)\n",
    "vdata = tsinfer.VariantData(\"PanTro-chr3-sim.vcz\", ancestral_allele=ancestral_allele)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa203717-7e97-4086-9d6f-ac4af9214c54",
   "metadata": {},
   "source": [
    "### The 3 steps of tsinfer\n",
    "\n",
    "_Tsinfer_ inference is split into 3 steps:\n",
    "1. Generating ancestors (ga): [`tsinfer.generate_ancestors()`](https://tskit.dev/tsinfer/docs/latest/api.html#tsinfer.generate_ancestors)\n",
    "2. Matching ancestors (ma): [`tsinfer.match_ancestors()`](https://tskit.dev/tsinfer/docs/latest/api.html#tsinfer.match_ancestors)\n",
    "3. Matching samples (ms): [`tsinfer.match_samples()`](https://tskit.dev/tsinfer/docs/latest/api.html#tsinfer.match_samples)\n",
    "\n",
    "We can run all three in one go by calling `tsinfer.infer()`, but it's more flexible to run them separately, and allows you to save intermediate results, which is useful for large inferences. You can use the `progress_monitor` argument to see how long the steps will take, and the `num_threads` argument to use more CPU cores on your computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15017ad0-1120-449a-9c0e-97da460b9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_params = {\n",
    "    \"num_threads\": 6,  # Set to the number of cores on your computer. E.g. a macbook air M2 has 8\n",
    "    \"progress_monitor\": True,\n",
    "}\n",
    "ancestors = tsinfer.generate_ancestors(vdata, **general_params)\n",
    "ancestors_ts = tsinfer.match_ancestors(vdata, ancestors, **general_params)\n",
    "ts = tsinfer.match_samples(vdata, ancestors_ts, **general_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8de030-5fc6-4bd9-8b94-8c63100330c7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The inferred tree sequence should encode exactly the same genotype data as the original (although the genealogy may be different). However, since the topology is different, it may require different numbers of mutations at any one site to encode the data\n",
    "\n",
    "Note: this isn't strictly true, as the original dataset may contain missing data, which is imputed by tsinfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ea7736-7b6d-4911-b5f1-008b479df210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"simulation diversity = {simulated_ts.diversity():.6f}, diversity in inferred ts = {ts.diversity():.6f}\")\n",
    "print(f\"simulation num_sites = {simulated_ts.num_sites}, num_sites in inferred ts = {ts.num_sites}\")\n",
    "print(f\"simulation num_mutations = {simulated_ts.num_mutations}, num_mutations in inferred ts = {ts.num_mutations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10e6ce-6f2a-4538-ad25-bd79d0d0cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Since the tsinferred tree sequence does not have meaningful node times, we cannot run branch-length statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e2a7a5-e8cf-4a27-8933-9906c6361799",
   "metadata": {},
   "source": [
    "## Tsdate: an HMM on a graph\n",
    "\n",
    "Dating is fast (although importing tsdate for the first time can take a minute or two). There's no need to parallelise across threads.\n",
    "\n",
    "TODO: briefly explain how tsdate works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c6896-2fc8-46b4-9bbc-8675f84f8c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsdate\n",
    "undated_ts = tsdate.preprocess_ts(ts)\n",
    "dated_ts = tsdate.date(undated_ts, mutation_rate=model.mutation_rate, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ae484-c12f-46e0-93d6-94d649a5b8f2",
   "metadata": {},
   "source": [
    "We can now plot ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276e751-dc3b-4780-a668-f42f903f171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "def node_time_below_oldest_muts(ts):\n",
    "    # As there are slightly different numbers of mutations, we can't simply compare mutation times\n",
    "    # Instead, we compare the oldest mutation at each site, and take the time of the node below that\n",
    "    return np.array(\n",
    "        [ts.nodes_time[s.mutations[0].node] if len(s.mutations) else np.nan for s in ts.sites()]\n",
    "    )\n",
    "\n",
    "def plot_log_times(orig_ts, new_ts):\n",
    "    orig_time_oldest_mut_node = node_time_below_oldest_muts(orig_ts)\n",
    "    new_time_oldest_mut_node = node_time_below_oldest_muts(new_ts)\n",
    "    use = np.logical_and(orig_time_oldest_mut_node > 0, new_time_oldest_mut_node > 0)\n",
    "    x = np.log10(orig_time_oldest_mut_node[use])\n",
    "    y = np.log10(new_time_oldest_mut_node[use])\n",
    "    plt.hexbin(x, y, bins='log')\n",
    "    plt.axline((0, 0), slope=1, color=\"red\")\n",
    "    plt.xlabel(\"True node time (generations)\")\n",
    "    plt.ylabel(\"Inferred node time (generations)\")\n",
    "    plt.text(0, 5, f\"r2 = {np.corrcoef(x, y)[0,1] ** 2:.5f}\")\n",
    "    # set log ticks\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x,y: f'{10**x:.0f}'))\n",
    "    plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x,y: f'{10**x:.0f}'))\n",
    "\n",
    "plot_log_times(ts, dated_ts)\n",
    "plt.title(\"First round of inference\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32009e7f-773c-40a6-abbd-030e0129ae2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If we want to change anything (e.g. use different times), we can simply make a new VariantData object (this is efficient and instantaneous)\n",
    "vdata = tsinfer.VariantData(\"PanTro-chr3-sim.vcz\", ancestral_allele=ancestral_allele, sites_time=node_time_below_oldest_muts(dated_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476498d-51d4-4c47-85f3-c58c56f5f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_ts = tsinfer.infer(vdata, num_threads=4, progress_monitor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7609765-22c4-4803-80b2-33633dfad26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "undated_ts = tsdate.preprocess_ts(inferred_ts)\n",
    "redated_ts = tsdate.date(undated_ts, mutation_rate=model.mutation_rate, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af931b7-5689-41dd-951a-a64c93a0a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_times(ts, redated_ts)\n",
    "plt.title(\"After one round of redating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a069f32-414e-44aa-bb5b-968750f0dee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b3d14-f61b-402c-b49f-bcd970faa35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With just the topology, you can look at the GNN, or count the types of topology:\n",
    "ts.genealogical_nearest_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2544313-8555-4a8b-9008-feee9665e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04453e5-4220-49af-8a32-3d678bde0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dts.node(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9d5e5-4cdc-4dd6-bd4b-d74f3363b87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b341a-c03a-4744-9df3-b71dbbe6d40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa1d97ed-9861-4ede-a3b9-30f328445fc8",
   "metadata": {},
   "source": [
    "## Testing inference accuracy\n",
    "\n",
    "There isn't an obvious way to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c9f6d-5880-44ae-97dd-c4187b6ca5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8fb9c-ac53-4e62-8cb5-49110dc95159",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = np.linspace(0, ts.sequence_length, 20)\n",
    "plt.stairs(ts.diversity(mode=\"branch\", windows=windows), windows, label=\"true branch AFS\")\n",
    "plt.stairs(redated_ts.diversity(mode=\"site\", windows=windows) / model.mutation_rate, windows, label=\"tsinfer + tsdate site AFS\")\n",
    "plt.stairs(redated_ts.diversity(mode=\"branch\", windows=windows), windows, label=\"tsinfer + tsdate branch AFS\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0832c81a-9781-4608-9354-a788db6f398f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
