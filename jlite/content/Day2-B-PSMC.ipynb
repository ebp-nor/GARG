{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b825ca5-56f8-463a-b272-e6e31de08c6a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To access material for this workbook please execute the two notebook cells immediately below (e.g. use the shortcut <b>&lt;shift&gt;+&lt;return&gt;</b>). The first cell can be skipped if you are running this notebook locally and have already installed all the necessary packages. The second cell should print out \"Your notebook is ready to go!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc9395-655a-42a0-ac17-ab2b73d009be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pyodide_kernel' in str(get_ipython()):  # specify packages to install under JupyterLite\n",
    "    raise RuntimeError(\"This workbook is not designed to run in JupyterLite. Please use a Colab or local install\")\n",
    "elif 'google.colab' in str(get_ipython()):  # specify package location for loading in Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %run /content/drive/MyDrive/GARG_workshop/Notebooks/add_module_path.py\n",
    "else:  # install packages on your local machine (-q = \"quiet\": don't print out installation steps)\n",
    "    !python -m pip install -q -r https://github.com/ebp-nor/GARG/raw/main/jlite/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e762a2-3e0a-420e-9d79-f83c337aa9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load questions etc for this workbook\n",
    "from IPython.display import SVG\n",
    "import tskit\n",
    "import ARG_workshop\n",
    "workbook = ARG_workshop.Workbook2B()\n",
    "display(workbook.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65c0e5-86d2-49d8-a8fd-2cce003fd0cf",
   "metadata": {},
   "source": [
    "### Using this workbook\n",
    "\n",
    "This workbook is intended to be used by executing each cell as you go along. Code cells (like those above) can be modified and re-executed to perform different behaviour or additional analysis. You can use this to complete various programming exercises, some of which have associated questions to test your understanding. Exercises are marked like this:\n",
    "<dl class=\"exercise\"><dt>Exercise XXX</dt>\n",
    "<dd>Here is an exercise: normally there will be a code cell below this box for you to work in</dd>\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e6bf1-e9f2-4cb7-a78d-8243ca0f74d6",
   "metadata": {},
   "source": [
    "# Workbook 2-B: pairwise inference\n",
    "\n",
    "The simplest ARG just consists of a pair of sample nodes, linked to a set of root nodes (sometimes called a \"cherry\" by phylogeneticists). There are no topological differences between the local trees, just a change in root height. Here's an example visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e4fcf-fd27-45ee-b262-2b33d382af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime\n",
    "import math\n",
    "ts = msprime.sim_ancestry(1, population_size=1e5, sequence_length=5e3, recombination_rate=1e-8, random_seed=2)\n",
    "\n",
    "# Snazzy 3D code taken from https://tskit.dev/tutorials/viz.html#d-effects\n",
    "tree_width, height = 100, 200\n",
    "y_step = 40  # Stagger between trees (i.e. 0 for all trees in a horizontal line)\n",
    "skew = 0.3  # How skewed the trees are, in radians\n",
    "n = ts.num_trees\n",
    "width = tree_width * n + 20 + 20  # L & R margins\n",
    "angle = math.atan(y_step/tree_width)\n",
    "ax_mv = y_step, (n - 1) * y_step + math.tan(skew) * (tree_width * .9)\n",
    "style = f\".x-axis {{transform: translate({ax_mv[0]}px, {ax_mv[1]}px) skewY(-{angle}rad)}}\"\n",
    "for i in range(ts.num_trees):\n",
    "    style += f\".tree.t{i} > .plotbox {{transform:translateY({(n - i - 1) * y_step}px) skewY({skew}rad)}}\"\n",
    "canvas_size = (width + y_step, height + ts.num_trees*y_step + math.tan(skew)*tree_width)\n",
    "ts.draw_svg(size=(width, height), x_scale=\"treewise\", style=style, canvas_size=canvas_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b12877-b5ad-48e9-a6e9-233413967272",
   "metadata": {},
   "source": [
    "You will see that the distances spanned by each tree can be quite variable (we have spaced them out evenly for visualization purposes, but e.g. the last tree only spans 38 bp out of this 5000bp genome.\n",
    "\n",
    "As we previously saw, each coalescence point (i.e. MRCA, or root of the) can be surprisingly long ago. In a typical species, we might expect a pair of haploid genomes to contain tens of thousands of different roots on each reasonably sized chromosome. In a species such as humans, hundreds of thousands, or even millions of coalescent points are responsible for causing the variation between a pair of genomes. _Pairwise_ approaches, as long as they encompass the whole genome, are therefore a surprisingly informative source of information for inferring population history.\n",
    "\n",
    "However, if we try to pair evey haploid genome with every other haploid genome, the scaling becomes quadratic, and therefore infeasible for large datasets. Fortunately, most organisms are *diploid*, and therefore it is quite reasonable to compare the two parental genomes in a single individual (after all, we know that they are likely to be from the same population, unless there has been very recent admixture). We can even do this for a large number of different individuals, for comparison.\n",
    "\n",
    "This is the basic premise pioneered by Heng Li and Richard Durbin, in their classic [2011 paper](https://www.nature.com/articles/nature10231), associated with their [PSMC](https://github.com/lh3/psmc) software. Several elaborations on the basic method have been made, and there has been a burst of recent activity in the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37b12d-49f2-42ee-a568-85a6ce56c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute code block with <shift>+Return to display question; type and press return, or click on the buttons to answer\n",
    "workbook.question(\"smc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e3c291-8534-408a-9e33-22fb34cc5470",
   "metadata": {},
   "source": [
    "## The idea behind PSMC\n",
    "\n",
    "A major reason behind the success of PSMC-like methods is that there is no complex topology to infer. All that needs doing is to infer the (unknown) *time* of the MRCAs as we go along the genome. Compared to ARG inference methods that estimate topology (e.g. _tsinfer_) separately from node times (_tsdate_), it is basically equivalent to running only the second, dating step; as we'll see in the next workbook, that tends to be very fast.\n",
    "\n",
    "If the SMC approximation holds, this allows a classic way to estimate hidden or unknown variables, using Hidden Markov Models (HMMs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20106043-e12a-4456-beab-dcc81af2eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute code block with <shift>+Return to display question; type and press return, or click on the buttons to answer\n",
    "workbook.question(\"hmm_psmc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f733bd-9706-4b18-98b5-5326c5294e63",
   "metadata": {},
   "source": [
    "## Classic PSMC-like software\n",
    "\n",
    "The original _PSMC_ software is still  and widely used, although it's now recommended to move to [MSMC2](https://github.com/stschiff/msmc2), e.g. see [this tutorial](https://evomics.org/learning/population-and-speciation-genomics/2020-population-and-speciation-genomics/demography-psmc-msmc/) by Richard Durbin, from whose group these two methods emerged.\n",
    "\n",
    "We may encounter some of the bleeding edge methods like [Phlash](https://pubmed.ncbi.nlm.nih.gov/38585997/), [cobraa](https://www.biorxiv.org/content/10.1101/2024.03.24.586479v1.full.pdf), and [Gamma-SMC](https://genome.cshlp.org/content/33/7/1023) in the session tomorrow. However, for simple teaching purposes, this workbook will use a [python-only reimplementation](https://github.com/tulerpetontidae/psmc-python) of PSMC, which can take tree sequences as input. Thanks to Artem Lomakin for making this available: a copy of the code has been placed in the `pmsc_python` folder in the current directory.\n",
    "\n",
    "We will follow the [psmc-python example notebook](https://github.com/tulerpetontidae/psmc-python/blob/main/example-tskit.ipynb) and download some data stored in _tskit_ format from the [Unified genealogy](https://www.science.org/doi/10.1126/science.abi8264). We will then re-infer MRCAs for individuals using PSMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f6997-a0f6-48f7-960d-5aa86e1a8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "chrom = \"17_q\"  # Q arm of chr 17\n",
    "file = f\"hgdp_tgp_sgdp_chr{chrom}.dated.trees.tsz\"\n",
    "url = f\"https://zenodo.org/records/5495535/files/{file}\"\n",
    "path = os.path.join(\"data\", file)\n",
    "if not os.path.exists(path):\n",
    "    with workbook.download(url) as t:\n",
    "        urllib.request.urlretrieve(url, filename=path, reporthook=t.update_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b341a-c03a-4744-9df3-b71dbbe6d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tszip\n",
    "import json\n",
    "\n",
    "# Open and pick some selected genomes\n",
    "ts = tszip.decompress(path).trim()  # remove the missing flanking regions\n",
    "# Make a dict of 5 individuals from different populations, taken from the HGDP data\n",
    "# Feel free to pick some others\n",
    "use_pops = {\"Biaka\", \"Mbuti\", \"San\", \"Japanese\", \"Uygur\", \"French\"}\n",
    "all_pops = set()\n",
    "individuals = {}\n",
    "for i in ts.individuals():\n",
    "    metadata = json.loads(i.metadata.decode())\n",
    "    if metadata.get(\"sample\", \"\").startswith(\"HGDP\"):\n",
    "        # This is an HGDP individual (could also try with SGDP or 1000genomes)\n",
    "        pop = ts.population(ts.node(i.nodes[0]).population)\n",
    "        pop_metadata = json.loads(pop.metadata.decode())\n",
    "        name = pop_metadata[\"name\"]\n",
    "        all_pops.add(name)\n",
    "        if name in use_pops:\n",
    "            print(f\"Using {metadata['sample']} from {pop_metadata}\")\n",
    "            individuals[name + \"-\" + pop_metadata[\"region\"]] = i.id\n",
    "            use_pops.remove(name)\n",
    "print(f\"Other populations you could choose from: {all_pops - use_pops}\")\n",
    "print(f\"Couldn't find {use_pops} in {all_pops}\" if len(use_pops) else f\"Individual IDs: {individuals}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aaf5af-1f70-422a-961b-6bd0165e1c10",
   "metadata": {},
   "source": [
    "To get reasonable results, you would normally run PSMC on a large number of chromosomes, simultaneously. This can take some time, although more modern software packages can speed this up (for real analysis, you are recommended to use something like Phlash rather than psmc-python, which is even slower than the original psmc).\n",
    "\n",
    "The original PSMC algorithm uses a bespoke FASTA-like format in which the entire genome binned into 100bp windows, and the windows are classified according to whether they have a heterozygous site or not. This rather customised discretisation is followed in the implementation below (when converting a tree sequence into an input data array to save). Other PSMC-like approaches may differ in this respect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e08c0-8a4a-4928-abc5-34977349df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psmc_python.utils import process_ts\n",
    "import numpy as np\n",
    "\n",
    "# get an `x` object for input into psmc-python: normally this is of shape\n",
    "# num_chromosomes x num_windows. Here we are just using a single chromosome, for speed.\n",
    "for name in individuals.keys():\n",
    "    x = process_ts(ts, individual=individuals[name], progress=True)\n",
    "    outfile = os.path.join(\"data\", name + \".npy\")\n",
    "    print(f\"Saved {x.shape[1]} 100bp windows into '{outfile}' for {x.shape[0]} chromosome(s)\")\n",
    "    np.save(outfile, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d638291-4041-48fd-8342-199192992931",
   "metadata": {},
   "source": [
    "PSMC uses discrete time bins, and for speed, merges some of the time bins together. The `pattern` argument specifies how to do this and the Li & Durbin recommend a [particular incantation for the autosomes](https://github.com/tulerpetontidae/psmc-python/issues/5), which we will use here without further comment. There has been a recent move towards reducing the effect of discrete bins, either by using a parameterised distribution (e.g. beta or gamma) or by sampling time bin boundaries themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfbfe53-80bd-491e-9830-7b9de85897f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function is also defined in workbook.run_psmc, which allows running in windows\n",
    "# See https://bobswinkels.com/posts/multiprocessing-python-windows-jupyter/\n",
    "def run_psmc(params):\n",
    "    from psmc_python.model import PSMC\n",
    "\n",
    "    data_file = params[0]\n",
    "    data = np.load(data_file)\n",
    "    n_iter = params[1] if len(params) > 1 else 10\n",
    "    start_window = params[2] if len(params) > 2 else 0\n",
    "    end_window = params[3] if len(params) > 3 else data.shape[1]\n",
    "    data = data[:, start_window: end_window]\n",
    "    print(f\"Using {data.shape[1]} 100bp windows for inference\", flush=True)\n",
    "    theta0 = np.sum(data) / (data.shape[0] * data.shape[1])\n",
    "    rho0 = theta0 / 5\n",
    "\n",
    "    # initialise new instance and run EM - do not show a progress bar, as it doesn't\n",
    "    # work when run in parallel\n",
    "    psmc_model = PSMC(t_max=15, n_steps=64, pattern='1*4+25*2+1*4+1*6', progress_bar=None)\n",
    "    psmc_model.param_recalculate()\n",
    "\n",
    "    initial_params = [theta0, rho0, 15] + [1.] * (psmc_model.n_free_params - 3)\n",
    "    bounds = [(1e-4, 1e-1), (1e-5, 1e-1), (12, 20)] + [(0.1, 10)] * (psmc_model.n_free_params - 3)\n",
    "    name = data_file.replace(\".npy\", \"\")\n",
    "    loss_list, params_history = psmc_model.EM(initial_params, bounds, x=data, n_iter=n_iter, name=name)\n",
    "    psmc_model.save_params(name + \".json\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ee07d-5deb-4d82-8efa-e6b3d402b38c",
   "metadata": {},
   "source": [
    "We can now run the EM algorithm. This runs 5 iterations of the EM algorithm for each individual. Each iteration can\n",
    "take about 5 minutes, so may may take 25 minutes for each individual. At least we can parallelize all 6 individuals on separate cores, which is what the `multiprocessing.Pool` invocation does.\n",
    "\n",
    "Go and have a cup of tea or coffee while it runs, or read up on the [original PSMC paper](https://www.nature.com/articles/nature10231) (short and readable) or in a blog post [discussing population structure](https://www.molecularecologist.com/2016/05/18/opening-pandoras-box-psmc-and-population-structure/). Note that [a recent preprint](https://www.biorxiv.org/content/10.1101/2024.03.24.586479v1.full) describing the cobraa software indicates that there is more information available in the $T_\\mathrm{MRCA}$s that could help distinguish between changes in ancient structure and true changes in population size. We may wish to discuss the implications of this in a collaborative session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2324304-6a56-4d53-95ef-385ff77dc0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "# Only choose e.g. 100_000 x 100bp windows. You can change this (or omit it) to include\n",
    "# more of the genome in order to increase accuracy, but it will take longer to run\n",
    "start_window_idx = 100_000\n",
    "end_window_idx = 500_000\n",
    "task_params = [\n",
    "    (\n",
    "        os.path.join(\"data\", name) + \".npy\",\n",
    "        5,  # Number of EM iterations\n",
    "        start_window_idx,\n",
    "        end_window_idx\n",
    "    ) for name in individuals.keys()\n",
    "]\n",
    "\n",
    "with Pool(processes=6) as pool:  # set to between 1 and the number of CPU cores on your machine\n",
    "    _ = pool.map(workbook.run_psmc, task_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674ce1d-9f52-47de-bf85-a90387e2641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from psmc_python.plot import plot_history\n",
    "from psmc_python.model import PSMC\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(12,6))\n",
    "psmc = PSMC()\n",
    "afr_colours = iter(('tomato', 'orangered', 'darkorange'))\n",
    "other_colours = iter(('skyblue', 'dodgerblue', 'cornflowerblue'))\n",
    "for subpop, sample_id in individuals.items():\n",
    "    color=next(afr_colours if subpop.endswith(\"AFRICA\") else other_colours)\n",
    "    psmc.load_params(os.path.join(\"data\", subpop + \".json\"))\n",
    "    plot_history(psmc, th=20, axs=axs, label=subpop + f\" (sample {sample_id})\", color=color)\n",
    "        \n",
    "axs.set_ylim(0,2.5e4);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580cd9b-3e6b-4e54-a4f8-3b19f07c8b10",
   "metadata": {},
   "source": [
    "According to Heng Li, the PSMC author, [\"Not correcting for low coverage is the most common pitfall when using PSMC.\"](https://github.com/lh3/psmc). However, these data are based on WGS should should be robust to this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f9f2a9-ee9d-41de-a3fa-5239e9f82e77",
   "metadata": {},
   "source": [
    "## Other useful HMMs\n",
    "\n",
    "On the topic of HMMs, it's worth mentioning another now-classic HMM: the Li & Stephens HMM. There will be a talk on this later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
