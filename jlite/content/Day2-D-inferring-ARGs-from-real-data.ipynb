{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce9e495e-2e17-40bf-9049-aeabca0099de",
   "metadata": {
    "id": "VpWXVCgis7xa"
   },
   "source": [
    "# Setup\n",
    "\n",
    "To access material for this workbook please execute the two notebook cells immediately below (e.g. use the shortcut <shift>+<return>). The first cell can be skipped if you are running this notebook locally and have already installed all the necessary packages. The second cell should print out \"Your notebook is ready to go!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6c46d0-8961-435b-9ea0-064102df5fb2",
   "metadata": {
    "id": "VpWXVCgis7xa"
   },
   "outputs": [],
   "source": [
    "if 'pyodide_kernel' in str(get_ipython()):  # specify packages to install under JupyterLite\n",
    "    raise RuntimeError(\"This workbook is not designed to run in JupyterLite. Please use a Colab or local install\")\n",
    "elif 'google.colab' in str(get_ipython()):  # specify package location for loading in Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %run /content/drive/MyDrive/GARG_workshop/Notebooks/add_module_path.py\n",
    "else:  # install packages on your local machine (-q = \"quiet\": don't print out installation steps)\n",
    "    # (NB: you can probably ignore any message about restarting the kernel)\n",
    "    !pip install -q -r https://github.com/ebp-nor/GARG/raw/main/jlite/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbc248-13ce-4dcb-98cc-2c59a489eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load questions etc for this workbook\n",
    "import ARG_workshop\n",
    "workbook = ARG_workshop.Workbook2D()\n",
    "display(workbook.setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816362b-45de-406e-a764-a9911d1691d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsinfer\n",
    "import subprocess\n",
    "import sys\n",
    "import zarr\n",
    "import pandas as pd\n",
    "import tskit\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c4b8dc-71a2-4f39-a616-621c34b246fb",
   "metadata": {},
   "source": [
    "### Using this workbook\n",
    "\n",
    "This workbook is intended to be used by executing each cell as you go along. Code cells (like those above) can be modified and re-executed to perform different behaviour or additional analysis. You can use this to complete various programming exercises, some of which have associated questions to test your understanding. Exercises are marked like this:\n",
    "<dl class=\"exercise\"><dt>Exercise XXX</dt>\n",
    "<dd>Here is an exercise: normally there will be a code cell below this box for you to work in</dd>\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3068221a-7eda-4997-ad0d-f48752fc34b7",
   "metadata": {},
   "source": [
    "# Workbook 2-D: inferning ARGs from real data\n",
    "\n",
    "In this lab session we will infer ARGs from real data, using the House sparrow system as an example. You can also consult the [tsinfer documentation](https://tskit.dev/tsinfer/docs/stable/index.html) and the [tsinfer tutorial](https://tskit.dev/tsinfer/docs/stable/tutorial.html) for more information and examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9a0231-c65d-473e-8000-10e7e89e86d5",
   "metadata": {},
   "source": [
    "## Input data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8160ee67-60b0-4839-ae2c-38ecee9531da",
   "metadata": {},
   "source": [
    "### Sparrow data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6102d8d6-8437-4621-b112-252dfc5a2b98",
   "metadata": {},
   "source": [
    "In this workbook we will look at data based on the House sparrow (*Passer domesticus*) system. House sparrows are an anthrodependent species and have spread all over the world, but little is known about their origin. [A recent publication](https://royalsocietypublishing.org/doi/10.1098/rspb.2018.1246) studied three Eurasian species, including populations from the Bactrianus sparrow that serves as ancestral proxy for house sparrows, with an inferred split between commensal house and Bactrianus occuring ~11kya. The publication identified putative regions for adaptation to an anthropogenic niche, one of which occurs on chromosome 8. The example data in this workbook is based on a region on [chromosome 8 that has a strong signal of divergence](https://royalsocietypublishing.org/cms/asset/df530257-c8ec-4a9f-945c-23dfdede4a23/rspb20181246f04.jpg) between bactrianus and House sparrows. This region harbors a gene, AMY2A, that encodes the amylase enzyme which helps digest starch that presumably became more abundant with the advent of agriculture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f354a-a47f-49ca-a581-c612156a5081",
   "metadata": {},
   "source": [
    "### Convert BCF to vcz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2497ea-7686-42a5-8ac2-0d9cbc6899b3",
   "metadata": {},
   "source": [
    "The raw data is provided in binary Variant Call Format (VCF) and consists of phased bi-allelic SNP calls, which is a [requirement for tsinfer analyses](https://tskit.dev/tsinfer/docs/stable/inference.html#data-requirements). Even though tsinfer supports loading VCF/BCF data, the [current trend is to move toward other data storage formats, such as the Zarr format](https://www.biorxiv.org/content/10.1101/2024.06.11.598241v1.full), as the variant call format does not allow for easy retrieval of data based on subsets of samples or fields. The [Zarr format](https://zarr.dev/) stores data in arrays in a data store (directory) and is designed to efficiently subset data in different ways, for instance making it easy to mask samples or sites without tampering with the raw data. The [bio2zarr Python module](https://sgkit-dev.github.io/bio2zarr/intro.html) has recently been released as a tool to convert various bionformatics data formats to Zarr format. Here we will use the `vcz` suffix to designate Zarr data stores. Run the code below to convert BCF to Zarr format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eedf734-dddc-47db-ae02-b0f764ac54ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_name = \"data/chr8.subset.bcf\"\n",
    "zarr_file_name = \"data/chr8.vcz\"\n",
    "try:\n",
    "    subprocess.run([sys.executable, \"-m\", \"bio2zarr\", \"vcf2zarr\", \"convert\", \"--force\", vcf_name, zarr_file_name])\n",
    "except FileNotFoundError:\n",
    "    print(\"Please install bio2zarr to convert VCF to Zarr by running !pip install bio2zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46afddd1-3f6d-4fa5-8ce7-6ed262ae9f6e",
   "metadata": {},
   "source": [
    "We can load the data store with the `zarr` Python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc244c3-8e2b-45ab-a8d1-1b6b7105a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = zarr.load(zarr_file_name)\n",
    "display(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3115588-4ea8-4aa6-af75-711e76a7c3d3",
   "metadata": {},
   "source": [
    "Basically, the `ds` data structure consists of arrays of data that can be accessed in a very efficient manner. If you peek into the zarr file (actually a directory) you will see that the variable names above simply reflect the folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4183c7-2665-4d88-9be2-6c034d2c281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/chr8.vcz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2944609-2aa3-4cb9-9714-3a6b56ea876c",
   "metadata": {},
   "source": [
    "in which each folder contains subfolders and binary arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fc742-0186-4704-a59c-ca8770870860",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree data/chr8.vcz | head  # Remove the pipe to head to see all files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917a102-9f31-4afe-8279-59443e15ed21",
   "metadata": {},
   "source": [
    "We don't really need to know these details as loading of the data store generates a convenient data object; suffice to say that if you look at the contents of the VCF file, you will that the columns and fields from the VCF map to the different variable names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d9062-5f5e-430f-9976-e69ae9b3a286",
   "metadata": {},
   "source": [
    "We can investigate the shape and type of the variables by accessing them similar to keys in a dict, showing that they are [numpy.ndarray](https://numpy.org/doc/1.26/reference/generated/numpy.ndarray.html)s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3b018-f3f4-43a8-9b23-41c53e092cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in [\"sample_id\", \"call_genotype\", \"variant_allele\"]:\n",
    "    print(key, ds[key].shape, ds[key].dtype, type(ds[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e0108-527b-4a4d-b80a-11b525a95717",
   "metadata": {},
   "source": [
    "Since the variables are arrays, we can subset them by [ndarray indexing](https://numpy.org/doc/1.26/user/basics.indexing.html#indexing-on-ndarrays):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e2599-8408-4be8-bd17-ba5e6a2751cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"sample_id\"][0:10], ds[\"call_genotype\"][0:4,0:4,:], ds[\"variant_allele\"][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858ac95-cb34-4d7c-9563-5e329bee931e",
   "metadata": {},
   "source": [
    "At this point we have samples and variant data, but we would like to add more metadata, such as population information about the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77b39d-189d-489d-89eb-8ccd96c18445",
   "metadata": {},
   "source": [
    "### Add individual and population metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e0cb9-de90-4ffe-85d9-1e2e62ed5aa8",
   "metadata": {},
   "source": [
    "Individual and population metadata are persistent (well, sort of) and can therefore be added to the Zarr store itself. We provide sample and population information in two tabular text files that we load below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34cdd5-013d-4c04-905d-2baa6017e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesfile = \"data/samples.tsv\"\n",
    "populationfile = \"data/populations.tsv\"\n",
    "\n",
    "population_df = pd.read_table(populationfile)\n",
    "samples_df = pd.read_table(samplesfile).set_index(\"sample\")\n",
    "schema = json.dumps(tskit.MetadataSchema.permissive_json().schema).encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c84d47-5824-4954-b76e-75d62706bb20",
   "metadata": {},
   "source": [
    "The last step defines a generic schema (basically [a data description format in JSON](https://json-schema.org/understanding-json-schema)) that is needed to initialize the metadata slots. \n",
    "The code below first loads the Zarr store, sets the schemas, and then adds metadata about samples and individuals. The only metadata we have is the link between individual and population, but any descriptive data could be added.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd64f7-6d5c-4c1a-969f-1b5ec0af8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = zarr.load(zarr_file_name)\n",
    "population_set = set(samples_df.loc[ds[\"sample_id\"]][\"population\"].values)  # populations table contains more samples than are present in Zarr file so take care not to add them\n",
    "\n",
    "# Save populations and individuals metadata\n",
    "zarr.save(f\"{zarr_file_name}/populations_metadata_schema\", schema)\n",
    "zarr.save(f\"{zarr_file_name}/individuals_metadata_schema\", schema)\n",
    "metadata = []\n",
    "\n",
    "for row in population_df.itertuples(index=False):\n",
    "    if row.population not in population_set:\n",
    "        # Uncomment print statements if you want to see what is added / skipped\n",
    "        # print(f\"Population {row.population} not present in samples; skipping\")\n",
    "        continue\n",
    "    data = json.dumps(row._asdict())\n",
    "    # print(f\"Adding population metadata: {data}\")\n",
    "    metadata.append(data.encode())\n",
    "zarr.save(f\"{zarr_file_name}/populations_metadata\", metadata)\n",
    "\n",
    "# Assign samples to population\n",
    "ds = zarr.load(zarr_file_name)\n",
    "num_individuals = ds[\"sample_id\"].shape[0]\n",
    "individuals_pop = np.full(num_individuals, tskit.NULL, dtype=np.int32)\n",
    "populations = [\n",
    "    json.loads(x.decode())[\"population\"] for x in ds[\"populations_metadata\"]\n",
    "]\n",
    "\n",
    "# Individual metadata here just consists of the population data, so in a way is redundant.\n",
    "# However, it is included to show that *any* metadata related to individuals could be added here, e.g., phenotype, geolocation, etc\n",
    "metadata = []\n",
    "for i, name in enumerate(ds[\"sample_id\"]):\n",
    "    pop = samples_df.loc[name].population\n",
    "    data = json.dumps(samples_df.loc[name].to_dict())\n",
    "    # print(f\"Individual {name}, population {pop}\")\n",
    "    individuals_pop[i] = populations.index(pop)\n",
    "    metadata.append(data.encode())\n",
    "    # print(f\"Adding individual metadata: {data}\")\n",
    "\n",
    "zarr.save(f\"{zarr_file_name}/individuals_population\", individuals_pop)\n",
    "zarr.save(f\"{zarr_file_name}/individuals_metadata\", metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb97d2c-11bd-471d-b77f-659185fdfb62",
   "metadata": {},
   "source": [
    "<dl class=\"exercise\"><dt>Exercise 1</dt>\n",
    "<dd>Load the data set and look at the 10 first entries of variables individuals_population and populations_metadata.</dd>\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd19ba-123b-40b5-954a-1066e0a62a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use zarr.load to load data set and print 10 first entries of individuals_population and populations_metadata. Recall that you can slice an array a with syntax a[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3289e-1898-449e-ae15-b3827b5fbbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute code block with <shift>+Return to display question; press on one of the buttons to answer\n",
    "workbook.question(\"metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b08e0-cff9-4fd5-bc51-b1717bb63579",
   "metadata": {},
   "source": [
    "## Set inference parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d417428-86fd-4b24-b681-bfc7aeaa3838",
   "metadata": {},
   "source": [
    "We have now added metadata to our data set, but before getting on with the inference itself, we need to load the variant data into a format that tsinfer understands. Moreover, we often want to change the inference parameters, such as excluding samples of poor quality, or filtering out sites that reside in problematic genomic regions. To this end, tsinfer defines a function [VariantData](https://tskit.dev/tsinfer/docs/latest/usage.html#variantdata-and-ancestral-alleles) that takes as arguments a variant data sources (VCF file name, ZARR store), and optionally user-defined sample masks, site masks, and even ancestral allele states stored in regular Python data structures. We create this information in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab18ae5-ea38-4203-acdb-2e76559e79ab",
   "metadata": {},
   "source": [
    "### Define ancestral allele state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e4e42e-97aa-4e15-bcb2-df8012c5fd60",
   "metadata": {},
   "source": [
    "An additional requirement of the input data is that the [ancestral state is known](https://tskit.dev/tsinfer/docs/stable/inference.html#data-requirements). This is not necessarily the same as the `REF` column in a VCF (or equivalently, the `0`th column of the `variant_allele` Zarr field). Most often, the sequence data has been mapped to a reference sequence from an individual in a focal population, and the allelic states of the reference could be derived alleles with respect to some outgroup population. Therefore, we need to determine the ancestral state somehow. Here we will adopt a simple method based on maximum parsimony, where we use outgroup samples contained in the data store to determine the ancestral allele. If a majority (say, 80%) of the outgroups are called as the `ALT` allele, we simply set the ancestral allele to the `ALT` allele, else we use the `REF` allele. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be9eae-f4a0-45bc-8ea5-849cdf9d690e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Note:</b> There are caveats to using maximum parsimony, as discussed in <a href=\"https://academic.oup.com/genetics/article/209/3/897/5930981\">Keightley and Jackson (2018)</a>, but nevertheless it is a widely used approach due to its simplicity. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdebd9e-f1e2-4e4b-8594-04c8a4cf2de9",
   "metadata": {},
   "source": [
    "As of `tsinfer 0.4.0a`, if the VCF contains a field called `variant_AA`, it will be converted to and treated as ancestral allele information by tsinfer. However, the flexibility of tsinfer allows you to calculate your own ancestral alleles and choose which version to use later on in the inference process. Our example data does not contain the `variant_AA` field so we must do the ancestral allele calculation anyway. As outgroup, we will use the `tree` population (see phylogeny below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc1a48-4ea1-49e1-816e-3a435eed893c",
   "metadata": {},
   "source": [
    "<center><img src=\"img/sparrows.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d012a9c-e82b-47f8-b23b-eb5f45b5b708",
   "metadata": {},
   "source": [
    "The following code shows how to do this based on samples belonging to the `tree` outgroup population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6abc6-39ad-4244-b5ab-26f8384e105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience generate two dictionaries that map from population name to id and the corresponding reverse mapping\n",
    "pop2id = {json.loads(x.decode())[\"population\"]:i for i, x in enumerate(ds[\"populations_metadata\"])}\n",
    "id2pop = {v:k for k, v in pop2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e510a58-182c-4d42-a3e4-08871e83d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices of the tree individuals\n",
    "tree_pop_indices = np.where(ds[\"individuals_population\"] == pop2id[\"tree\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e40ae2-48d6-421a-986d-7fe3e2ccd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outgroups = len(tree_pop_indices) * 2  # We have diploid samples so two alleles per outgroup individual\n",
    "threshold = 0.8  # Set a (customizable) threshold\n",
    "n_changes = 0\n",
    "ancestral_allele = ds[\"variant_allele\"][:, 0]  # The variant_allele variable holds the REF/ALT pairs for each bi-allelic SNP; initialize ancestral state to REF allele for all sites\n",
    "for i, gt in enumerate(tqdm(ds[\"call_genotype\"][:, tree_pop_indices, :])):  # numpy.ndarray multiindex slicing to select only tree individuals from second dimension (of three)\n",
    "    if sum(gt.flatten()) / n_outgroups >= threshold:\n",
    "        ancestral_allele[i] = ds[\"variant_allele\"][i, 1]  # Swap ancestral state to ALT if outgroups consistently called as ALT\n",
    "        n_changes = n_changes + 1\n",
    "print(f\"Ancestral allele: changed {n_changes} out of {len(ancestral_allele)} sites ({n_changes/len(ancestral_allele)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7136bd-cdf3-4023-8b1f-3f8a5260286b",
   "metadata": {},
   "source": [
    "One improvement you could make here is to identify sites where the outgroup \"votes\" are inconsistent. This information could be used to mask sites that are deemed untrustworthy. We refrain from doing so here, but in the next section, we setup a sample mask that restrict the inference to a sample subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d13f0f-acc2-4322-a368-31a54de98ec4",
   "metadata": {},
   "source": [
    "### Add sample masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61526aa3-0793-4266-821e-f2748708c757",
   "metadata": {},
   "source": [
    "We now define a sample mask to exclude samples belonging to the outgroup `tree` and the `iago` population (Cabo Verde sparrows). A mask array is a boolean array (`False`/`True`) where samples to be excluded are assigned `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0679df-408b-4e53-9b36-99decfa34efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mask = (ds[\"individuals_population\"] == pop2id[\"iago\"]) | (ds[\"individuals_population\"] == pop2id[\"tree\"])\n",
    "print(f\"Masking {sum(sample_mask)} samples from tree population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060dba0d-1fc2-4af4-aba9-a93a368a7849",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1439535-9503-43e0-bf11-615dc9260e1b",
   "metadata": {},
   "source": [
    "Now we have all the relevant information we need to proceed with inference. However, note how easy it would be to apply different sample masks or allelic states to update an inference: simply update the parameters that you pass to the `tsinfer.VariantData` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42fc12-063f-488c-a2c6-de9971bd6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a VariantData object. You can easily change parameters without having to modify the underlying data store.\n",
    "vdata = tsinfer.VariantData(zarr_file_name, ancestral_allele=ancestral_allele, sample_mask=sample_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09372c8a-7c3f-43b6-8ddb-eb758a452824",
   "metadata": {},
   "source": [
    "The `VariantData` object is then passed on to [tsinfer.infer](https://tskit.dev/tsinfer/docs/stable/api.html#tsinfer.infer) that runs the [full inference pipeline](https://tskit.dev/tsinfer/docs/stable/inference.html#sec-inference). With one thread, this may take up to ten minutes, so meanwhile, take a break or increase the number of threads if you can and are impatient!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0903dfe-2c1d-4594-8d76-eb32dd7befad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Note:</b> Although there is functionality to run the full pipeline in a simple function call, it is not recommended to do so in more complex settings. For instance, if the ancestor matching step (<code>ma-match</code>) takes long to complete, a potential solution is to trim ancestors with <a href=\"https://tskit.dev/tsinfer/docs/stable/api.html#tsinfer.AncestorData.truncate_ancestors\">ancestors.truncate_ancestors</a>. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee0c6f-0696-47aa-aa03-6e6a73e3d464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ts = tsinfer.infer(vdata, num_threads=1, progress_monitor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec706593-6b1e-494e-8efe-647209604e03",
   "metadata": {},
   "source": [
    "The inference pipeline generates a tree sequence object that you by now should be familiar with. As a last inference step, we date the ancestral nodes of the tree sequence using [tsdate](https://tsdate.readthedocs.io/en/latest/index.html) using a [bird mutation rate of 2.3e-9](https://genome.cshlp.org/content/26/9/1211.short) mutations per site per year. The input to [tsdate.date](https://tskit.dev/tsdate/docs/latest/python-api.html#tsdate.date) must be a simplified tree. The function [tsdate.preprocess_ts](https://tskit.dev/tsdate/docs/latest/python-api.html#tsdate.preprocess_ts) does this, but can also do other things, like removing data-poor regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fef242-c493-49e4-8563-6c0577800787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsdate\n",
    "dated_ts = tsdate.date(tsdate.preprocess_ts(ts), mutation_rate=2.3e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c8a202-c9a1-43d8-aa8c-8b187633dc95",
   "metadata": {},
   "source": [
    "## Investigate tree sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2426c2-40e9-4e9f-9da2-d96b81ae606a",
   "metadata": {},
   "source": [
    "Start by taking a look at the tree sequence objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677478a-7a79-40e9-9ed1-9e223734e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ts), display(dated_ts);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc9eca-18bc-4c4c-85c6-9eeb92caa496",
   "metadata": {},
   "source": [
    "Note the difference in time units! Also, even though the raw BCF consisted of variation data from a subregion 18.7-19.7Mbp, the sequence length of the tree sequence objects is 19699968bp, corresponding to the coordinate of the last variant. This length is **not** identical to the chromosome/contig length; chromosome 8 is 49Mbp long."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628eae7e-f886-4eb6-a896-612d5216432b",
   "metadata": {},
   "source": [
    "### Quality control with tsqc\n",
    "\n",
    "At this point it is good to assess the quality of the trees, for instance by looking at edge plots like we did previously. Instead of repeating the code for plots here, you could use the [tsqc](https://github.com/tskit-dev/tsqc) tool which makes interactive plots of edges and other quality indicators. It is primarily designed for use with very large samples. You can try it out on the tree sequence file by running (in your terminal!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a5bf6-dee5-4de3-84db-be9ff2c3b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy-paste code after the comment to a terminal. You probably need to install tsqc with the command python -m pip install git+https://github.com/tskit-dev/tsqc\n",
    "# python -m tsqc data/chr8.vcz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19027a-8e60-41f2-a28e-76f9a870f1eb",
   "metadata": {},
   "source": [
    "### Setup parameters for plotting windowed summary statistics\n",
    "\n",
    "Now that we have more populations to look at we add styling with more colors. Let's start by collecting the population metadata into a dictionary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e492678-1168-4c8e-aa52-af86635d9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "popmd = {p.id:p.metadata for p in ts.populations()}\n",
    "print(popmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94a82f-896c-441b-83f4-1f157cacb29f",
   "metadata": {},
   "source": [
    "Recall that we applied a sample mask to exclude `tree` and `iago` samples, but note that this information is retained in the tree sequence object. We add a color mapping to all populations nevertheless and keep track of the population ids present in the tree sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2debc96-59b9-46d5-ae21-34d00ec03165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import matplotlib.colors as mcolors  # Color library\n",
    "mpl_colors = mcolors.TABLEAU_COLORS\n",
    "pop_in_ts, count = np.unique(ts.individuals_population, return_counts=True)  # Get population ids and counts\n",
    "for pop, color in zip(ts.populations(), list(mpl_colors)[:9]):\n",
    "    popmd[pop.id][\"color\"] = color\n",
    "sample_sets = [ts.samples(i) for i in pop_in_ts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c84e79-2911-42d6-ab89-f827ac974589",
   "metadata": {},
   "source": [
    "As before, we also make a CSS style for use with subsequent tree sequence plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16016468-78ee-4f55-9ec3-ff4701a8cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = []\n",
    "for popid, md in popmd.items():\n",
    "    # target the symbols only (class \"sym\")\n",
    "    s = f\".node.p{popid} > .sym \" + \"{\" + f\"fill: {md['color']}\" + \"}\"\n",
    "    styles.append(s)\n",
    "    # print(f'\"{s}\" applies to nodes from population {md[\"population\"]} (id {popid})')\n",
    "css_string = \" \".join(styles)\n",
    "# print(css_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb63827f-74e2-4ae4-9804-624b03909aef",
   "metadata": {},
   "source": [
    "We finally define windows for our region of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01030c6c-b8d7-4df5-baa5-3d85280f5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10_000\n",
    "roi = (18_700_000, 19_700_000)  # Coordinates used to subset the original VCF\n",
    "start_index = int(roi[0] / window_size)  # we don't want to plot regions without data\n",
    "num_windows = int(roi[1] / window_size)\n",
    "window_size = ts.sequence_length / num_windows\n",
    "windows = np.linspace(0, roi[1], num_windows + 1)\n",
    "windows[-1] = ts.sequence_length\n",
    "ticks = np.arange(187, 198, 2) / 10  # Get tick marks in Mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c6c12-612c-4221-843d-49f9d8a344d7",
   "metadata": {},
   "source": [
    "### Windowed genetic diversity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f92bb7-0e8d-4998-b33d-c5bc48b8a0a9",
   "metadata": {},
   "source": [
    "We begin by plotting the windowed genetic diversity (aka `pi`), or sample heterozygosity. Diversity is calculated with the [diversity](https://tskit.dev/tskit/docs/stable/python-api.html#tskit.TreeSequence.diversity) function, which is a [one-way](https://tskit.dev/tskit/docs/stable/stats.html#one-way-methods) method that calculates a statistic on a single sample set. By providing a list of samples sets, we can calculate windowed for all populations on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53071372-0f15-4657-ac57-a0e4cd0fece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_win = ts.diversity(\n",
    "    sample_sets=sample_sets,\n",
    "    windows=windows,\n",
    ")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "for i, pop in enumerate(pop_in_ts):\n",
    "    x = pi_win[:, i]\n",
    "    plt.plot(range(len(windows[start_index:-1])), x[start_index:], color=popmd[pop][\"color\"], label=popmd[pop][\"population\"])\n",
    "plt.ylabel(\"Diversity (pi)\")\n",
    "ax.xaxis.set_ticks(np.arange(0, 101, 20))\n",
    "ax.xaxis.set_ticklabels(ticks)\n",
    "plt.xlabel(\"Position (Mbp)\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174cd8b-069f-42b3-a4e6-7f6cc42dead6",
   "metadata": {},
   "source": [
    "TODO: comment on low diversity in introduced_house"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d8be9b-47f1-4d5f-862f-cd23cd8e9768",
   "metadata": {},
   "source": [
    "### Tajima's D plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34696f7-9fe9-4dbf-93ad-1bf6f7c5c19d",
   "metadata": {},
   "source": [
    "Next we plot another one-way statistic, namely Tajima's D, to scan for signs of selection. As a rule of thumb, [values smaller than -2](https://en.wikipedia.org/wiki/Tajima%27s_D) are significant and could indicate signals of selective sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41c0b2-7c7f-47b4-9133-8c064ea9671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tajd_win = ts.Tajimas_D(\n",
    "    sample_sets=sample_sets,\n",
    "    windows=windows,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d337af-cdc9-453b-ba1a-2e351f224fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "for i, pop in enumerate(pop_in_ts):\n",
    "    x = tajd_win[:, i]\n",
    "    plt.plot(range(len(windows[start_index:-1])), x[start_index:], color=popmd[pop][\"color\"], label=popmd[pop][\"population\"])\n",
    "plt.ylabel(\"Tajima's D\")\n",
    "ax.xaxis.set_ticks(np.arange(0, 101, 20))\n",
    "ax.xaxis.set_ticklabels(ticks)\n",
    "plt.xlabel(\"Position (Mbp)\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ec67e-99db-4ba7-80f0-f0830deebf5d",
   "metadata": {},
   "source": [
    "### Fixation indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b257d5-1fea-4650-ab9d-294a54614b0c",
   "metadata": {},
   "source": [
    "The fixation index $F_{ST}$ is used to assess population differentiation and can identify differentiated regions. It is a [multi-way method](https://tskit.dev/tskit/docs/stable/stats.html#sec-stats-sample-sets-multi-way) that compares 2 or more samples. We therefore need to make pairs of sample sets. To avoid too many comparisons, we group the populations into species House, Italian, Spanish, and Bactrianus sparrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86b432-2aa3-4818-9fa9-722cb63ad877",
   "metadata": {},
   "outputs": [],
   "source": [
    "house = np.concatenate((ts.samples(0), ts.samples(1), ts.samples(3)))\n",
    "italian = np.concatenate((ts.samples(5), ts.samples(7)))\n",
    "spanish = ts.samples(2)\n",
    "bactrianus = ts.samples(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86676c4-36f3-4340-b68d-44ecedf25c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_sample_sets = [house, italian, spanish, bactrianus]\n",
    "pair_comparisons = [(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)]\n",
    "fst_win = ts.Fst(\n",
    "    sample_sets=paired_sample_sets,\n",
    "    indexes=pair_comparisons,\n",
    "    windows=windows,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686c96d-1ff0-43fc-b800-08015e45ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "comparisons = [\"house_vs_italian\", \"house_vs_spanish\", \"house_vs_bactrianus\", \"italian_vs_spanish\", \"italian_vs_bactrianus\", \"spanish_vs_bactrianus\"]\n",
    "for i, comp in enumerate(comparisons):\n",
    "    x = fst_win[:, i]\n",
    "    plt.plot(range(len(windows[start_index:-1])), x[start_index:], label=comp, color=list(mpl_colors.values())[i])\n",
    "ax.xaxis.set_ticks(np.arange(0, 101, 20))\n",
    "ax.xaxis.set_ticklabels(ticks)\n",
    "plt.xlabel(\"Position (Mbp)\")\n",
    "plt.ylabel(\"Fst\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6dfa23-0424-4af7-b3f1-85276e55219b",
   "metadata": {},
   "source": [
    "### Divergence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84034d8d-28fa-4c6d-a477-a6768608e845",
   "metadata": {},
   "source": [
    "Finally, we calculate and plot divergence ($D_{XY}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4c875-3dbc-47f3-83c5-e9461f8c444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dxy_win = ts.divergence(\n",
    "    sample_sets=[house, italian, spanish, bactrianus],\n",
    "    indexes=[(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)],\n",
    "    windows=windows,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9c3c5-68d3-4f30-a7e6-e103c9855a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "comparisons = [\"house_vs_italian\", \"house_vs_spanish\", \"house_vs_bactrianus\", \"italian_vs_spanish\", \"italian_vs_bactrianus\", \"spanish_vs_bactrianus\"]\n",
    "for i, comp in enumerate(comparisons):\n",
    "    x = dxy_win[:, i]\n",
    "    plt.plot(range(len(windows[start_index:-1])), x[start_index:], label=comp, color=list(mpl_colors.values())[i])\n",
    "plt.xlabel(\"Window\")\n",
    "plt.ylabel(\"Divergence (dxy)\")\n",
    "ax.xaxis.set_ticks(np.arange(0, 101, 20))\n",
    "ax.xaxis.set_ticklabels(ticks)\n",
    "plt.xlabel(\"Position (Mbp)\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3bdb1-58c2-4a80-b90d-c63bc495947e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tree sequence analyses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bee5c0-1c06-4592-82f7-bc4596ab7544",
   "metadata": {},
   "source": [
    "## GNN plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db322425-d569-4097-8c99-2c8b146749d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_listed_by_group = [ts.samples(population=pop_id) for pop_id in pop_in_ts]\n",
    "gnn = ts.genealogical_nearest_neighbours(ts.samples(), samples_listed_by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c95e6-bdf1-46b1-82be-6b6573717446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 2))\n",
    "nhap = gnn.shape[0]\n",
    "xlab = np.arange(nhap).astype(np.float64)  # Define x labels\n",
    "bottom = np.zeros(nhap)  # Keep track of the \"bottom\" coordinate\n",
    "for col, popid in enumerate(pop_in_ts):\n",
    "    y = gnn[:, col]\n",
    "    p = ax.bar(x=xlab, height=y, label=popmd[popid][\"population\"], bottom=bottom, color=popmd[popid][\"color\"])\n",
    "    bottom += y\n",
    "\n",
    "# Plot group separators\n",
    "groupsep = np.cumsum([0] + [len(x) for x in samples_listed_by_group])\n",
    "ax.vlines(groupsep, ymin=-0.1, ymax=1.1)\n",
    "# Print names of groups\n",
    "grouplabels = [popmd[i][\"population\"] for i in pop_in_ts]\n",
    "pos = [groupsep[i] - (groupsep[i]-groupsep[i-1])/2 for i in range(1, len(groupsep))]\n",
    "for x, lab in zip(pos, grouplabels):\n",
    "    ax.text(x, -0.1, lab, rotation=30, horizontalalignment=\"right\", verticalalignment=\"top\")\n",
    "\n",
    "ax.set_xlabel(\"Sample id (haplotype)\")\n",
    "ax.set_ylabel(\"GNN proportion\")\n",
    "ax.set_title(\"GNN proportions for all sample haplotypes.\")\n",
    "ax.legend(bbox_to_anchor=(1, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2283d0d-3abe-44bc-8e2b-f49912e484eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_ind = 150\n",
    "df = ARG_workshop.haplotype_gnn(ts, focal_ind, windows, samples_listed_by_group)\n",
    "df.columns = [popmd[i][\"population\"] for i in pop_in_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a3de6f-52ee-40cb-abda-978f36f826d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 2), sharex=True)\n",
    "\n",
    "for hap, index in zip([0, 1], [211, 212]):\n",
    "    ax = plt.subplot(index)\n",
    "    data = df[df.index.get_level_values(\"haplotype\") == hap]\n",
    "    bottom = np.zeros(data.shape[0])\n",
    "    for i, popid in enumerate(pop_in_ts):\n",
    "        p = ax.bar(data.index.get_level_values(\"start\"), data[popmd[popid][\"population\"]], width=window_size, label=popmd[popid][\"population\"], bottom=bottom, color=popmd[popid][\"color\"])\n",
    "        bottom += data[popmd[popid][\"population\"]]\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylabel(f\"Hap {hap}\")\n",
    "plt.suptitle(f\"GNN plot for focal individual {focal_ind}, {ts.population(ts.individuals_population[focal_ind]).metadata['population']} population\")\n",
    "plt.xlabel(\"Genome position (bp)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d08201-3cf8-4a92-9dd2-4a347ee00d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
